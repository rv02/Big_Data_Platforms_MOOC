{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". You can run all the tests with the validate button. If the validate command takes too long, you can also confirm that you pass all the tests if you can run through the whole notebook without getting validation errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd940108c418529a12962053d1dc767b",
     "grade": false,
     "grade_id": "cell-97231f8480b9c894",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For this problem set, we'll be using the Jupyter notebook:\n",
    "\n",
    "![](jupyter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "58d7ae67a0dfe0b0c4a0b2c880308564",
     "grade": false,
     "grade_id": "cell-2e0a627e22b76fe5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## GraphFrame Exercises\n",
    "Your job is to implement multiple small methods that analyze people's social data using [GraphFrames](https://graphframes.github.io/graphframes/docs/_site/index.html).\n",
    "\n",
    "We use a small sample data of \"socialgraph.dat\" from https://archive.org/download/201309_foursquare_dataset_umn/fsq.zip, inside the \"umn_foursquare_datasets\" folder.\n",
    "\n",
    "The \"socialgraph.dat\" file contains the social graph edges (connections) that exist between users. Each social connection consits of two users represented by two unique ids (first_user_id and second_user_id). The connnections are directed. Supposed we have data shown as:\n",
    "\n",
    "first_user_id | second_user_id \n",
    "---------------|----------------\n",
    "             1 |             2\n",
    "             2 |             1\n",
    "\n",
    "This data set shows that there is a connection from user1 (whose id is 1) to user2 (whose id is 2), and another connection from user2 to user1.\n",
    "             \n",
    "This link may be helpful: https://graphframes.github.io/graphframes/docs/_site/api/python/graphframes.html#module-graphframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7f5ab11dcd71560406142a14dd47a15",
     "grade": false,
     "grade_id": "cell-44104a3ba82b4229",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:43987)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:43987)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5e321d6a43ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local[*]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                         \u001b[0msparkConf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/conf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loadDefaults, _jvm, _jconf)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# JVM is created, so create self._jconf directly through JVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloadDefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mUserHelpAutoCompletion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         answer = self._gateway_client.send_command(\n\u001b[0m\u001b[1;32m   1693\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1029\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \"\"\"\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    984\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:43987)"
     ]
    }
   ],
   "source": [
    "from graphframes import GraphFrame\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import re\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master('local[*]')\\\n",
    "    .appName('main')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sampleFile = \"socialgraph_sample.dat\"\n",
    "\n",
    "# Path of smaller data set\n",
    "testFile = \"socialgraph_testsample.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ddb6305c66b39df5063941ec18f44f6",
     "grade": false,
     "grade_id": "cell-0249f92f12130c6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Variable and methods that will be used in more than one test\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Test if two arrays that contain Rows are equal\n",
    "def equalArray(array1, array2):\n",
    "    for i in range(0, len(array2)):\n",
    "        assert array1[i].asDict() == array2[i].asDict(), \"the row was expected to be %s but it was %s\" % (array2[i].asDict(), array1[i].asDict())\n",
    "\n",
    "# Test if two dataframes contain same rows\n",
    "def equalDF(df1, df2, *columns):\n",
    "    \n",
    "    # sort dfs before converting them to lists\n",
    "    array1 = df1.orderBy(list(columns)).collect()\n",
    "    array2 = df2.orderBy(list(columns)).collect()\n",
    "    equalArray(array1, array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1bda394fe43970285dc5fd35776432f8",
     "grade": false,
     "grade_id": "cell-9dd6e550095fc617",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Create Graph\n",
    "`createGraph` creates a GraphFrame. Use user_id as both vertex id and vertex attribute. Use number of unique connections between users as edge weight. \n",
    "\n",
    "Example: Supposed we have data shown below:\n",
    "\n",
    " first_user_id | second_user_id \n",
    "---------------|----------------\n",
    "             1 |             2\n",
    "             1 |             2\n",
    "             2 |             1\n",
    "             1 |             3\n",
    "             2 |             3\n",
    "            \n",
    "The graph should be:\n",
    "![](example.png)\n",
    "             \n",
    "param `path`: path of file whose data should be used to create the GraphFrame \n",
    "\n",
    "`return`: GraphFrame\n",
    "\n",
    "Hints:\n",
    "- You can load the file into RDD and use RDD transformations to extract and parse the data. \n",
    "- [Regex](https://docs.python.org/3.7/library/re.html#module-re) is extremely useful when parsing the data in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72b63cf9f44c599473ec1c1d8d401295",
     "grade": false,
     "grade_id": "cell-ae33ce9628fa40aa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def createGraph(path):\n",
    "    r = sc.textFile(path)\n",
    "    r = r.flatMap(lambda file: file.split(\"/n\"))\n",
    "    digit = re.compile('\\d')\n",
    "    r = r.filter(lambda row: row and digit.match(row[len(row) - 1]))\n",
    "    ids = r.flatMap(lambda row: row.split(\" \")).filter(lambda row: row and digit.match(row[0])).map(lambda x: (x, 1))\n",
    "    v = ids.toDF().dropDuplicates().withColumn('id', col('_1').cast('int'))\n",
    "    v = v.withColumn('name', col('id').cast('int'))\n",
    "    v = v.select('id', 'name')\n",
    "    edges = r.map(lambda row: row.split(\" \"))\n",
    "    edges = edges.map(lambda li: [x for x in li if x and digit.match(x[0])]).map(lambda pair: (tuple(pair), 1))\n",
    "    e = edges.reduceByKey(lambda a, b: a + b).map(lambda li: (li[0][0], li[0][1], li[1])).toDF(schema=['src', 'dst', 'relationship'])\n",
    "    e = e.withColumn('src', col('src').cast('int')).withColumn('dst', col('dst').cast('int'))\n",
    "    return GraphFrame(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f8b597ed88908844c96fefa26f3df6f",
     "grade": false,
     "grade_id": "cell-2fd8cccf73474e89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "graph = createGraph(sampleFile).persist()\n",
    "graph.vertices.show()\n",
    "graph.edges.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec4648c001f9b6254d29638675adb0b5",
     "grade": true,
     "grade_id": "cell-372b63367350d1f5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''createGraph tests'''\n",
    "\n",
    "import random\n",
    "\n",
    "correctVertices = sc.parallelize([Row(id=2, name=2),\n",
    "                                  Row(id=10, name=10),\n",
    "                                  Row(id=8, name=8),\n",
    "                                  Row(id=3, name=3),\n",
    "                                  Row(id=7, name=7),\n",
    "                                  Row(id=4, name=4),\n",
    "                                  Row(id=1, name=1),\n",
    "                                  Row(id=9, name=9)]).toDF()\n",
    "\n",
    "correctEdges = sc.parallelize([Row(src=2, dst=10, relationship=1),\n",
    "                               Row(src=2, dst=8, relationship=1),\n",
    "                               Row(src=3, dst=7, relationship=1),\n",
    "                               Row(src=3, dst=10, relationship=1),\n",
    "                               Row(src=2, dst=3, relationship=1),\n",
    "                               Row(src=10, dst=4, relationship=1),\n",
    "                               Row(src=4, dst=10, relationship=1),\n",
    "                               Row(src=4, dst=2, relationship=1),\n",
    "                               Row(src=1, dst=9, relationship=1),\n",
    "                               Row(src=1, dst=10, relationship=2),\n",
    "                               Row(src=7, dst=9, relationship=1),\n",
    "                               Row(src=1, dst=3, relationship=1),\n",
    "                               Row(src=10, dst=1, relationship=1)]).toDF()\n",
    "testGraph = createGraph(testFile).persist()\n",
    "testVertices = testGraph.vertices\n",
    "testEdges = testGraph.edges\n",
    "\n",
    "assert testVertices.count() == correctVertices.count(), \"the vertices count was expected to be %s but it was %s\" % (correctVertices.count(), testVertices.count())\n",
    "assert testEdges.count() == correctEdges.count(), \"the edges count was expected to be %s but it was %s\" % (correctEdges.count(), testEdges.count())\n",
    "equalDF(testGraph.vertices, correctVertices, \"id\")\n",
    "equalDF(testGraph.edges, correctEdges, \"src\", \"dst\", \"relationship\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "684929f0318e77f4f27621df8c2a4d16",
     "grade": false,
     "grade_id": "cell-fa3f8ed6925bb667",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Both Directions\n",
    "`bothDirections` finds pairs of users who are connected by an edge in both directions.\n",
    "\n",
    "param `graph`: GraphFrame containing social data (created by `createGraph`).\n",
    "\n",
    "`return`: DataFrame which has columns \"start\", \"end\" and \"connections\", corresponding to the  starting user id, ending user id and number of connections between two users. \n",
    "\n",
    "Example: Supposed we have a graph as below:\n",
    "![](example_bothConnections.png)\n",
    "The result should be\n",
    "\n",
    "|start|end|connections|\n",
    "|---|---|------------|\n",
    "| 10|  4|           1|\n",
    "|  4| 10|           1|\n",
    "|  1| 10|           2|\n",
    "| 10|  1|           1|\n",
    "\n",
    "Hint: Check the find function from [GraphFrames](https://graphframes.github.io/graphframes/docs/_site/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "502508e20f6a5719a17beb2d6e225e8f",
     "grade": false,
     "grade_id": "cell-7664eaca92375b77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def bothDirections(graph):\n",
    "    df = graph.find(\"(a)-[e]->(b); (b)-[e2]->(a)\")\n",
    "    df = df.withColumn('start', col('a').getItem('id')).withColumn('end', col('b').getItem('id')).withColumn('connections', col('e').getItem('relationship'))\n",
    "    return df.select('start', 'end', 'connections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "bothDirections(graph).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a1406f69de3efc31548b28b3a96bb8f",
     "grade": true,
     "grade_id": "cell-f30164452a8adcb2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c4e4f9cde949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m'''bothDirections tests'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m correctEdges = sc.parallelize([Row(start=10, end=4, connections=1),\n\u001b[0m\u001b[1;32m      4\u001b[0m                                \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mparallelize\u001b[0;34m(self, c, numSlices)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \"\"\"\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mnumSlices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumSlices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnumSlices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultParallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mdefaultParallelism\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m         reduce tasks)\n\u001b[1;32m    427\u001b[0m         \"\"\"\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultParallelism\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'sc'"
     ]
    }
   ],
   "source": [
    "'''bothDirections tests'''\n",
    "\n",
    "correctEdges = sc.parallelize([Row(start=10, end=4, connections=1),\n",
    "                               Row(start=4, end=10, connections=1),\n",
    "                               Row(start=1, end=10, connections=2),\n",
    "                               Row(start=10, end=1, connections=1)]).toDF()\n",
    "equalDF(bothDirections(testGraph), correctEdges, \"start\", \"end\", \"connections\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91d3ddc7108c8dc4fd25ae844a1e7967",
     "grade": false,
     "grade_id": "cell-b32c4330ee9a7009",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Most Active User\n",
    "`mostActiveUser` finds which user has the most outward connections. \n",
    "\n",
    "param `graph`: GraphFrame containing social data.\n",
    "\n",
    "return: id of user who has the most outward connections. Return the smallest id if more than one users have the same number of outward connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ada1c8a7779806a953e6d9f09327a10e",
     "grade": false,
     "grade_id": "cell-e8dc0feba642b7db",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mostActiveUser(graph):\n",
    "    max_connections: DataFrame = graph.edges\n",
    "    max_connections = max_connections.groupBy('src').sum('relationship')\n",
    "    max_connection = max_connections.groupBy().max('sum(relationship)').first()[0]\n",
    "    max_connections = max_connections.filter(col('sum(relationship)') == max_connection).sort('src')\n",
    "    return max_connections.first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "mostActiveUser(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b56b33514bec1aae4b623676fab4d2d",
     "grade": true,
     "grade_id": "cell-b22ae08851e69e51",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''mostActiveUser tests'''\n",
    "\n",
    "assert mostActiveUser(graph) == 5, \"the most active user was expected to be 5 but it was %s\" % mostActiveUser(graph)\n",
    "assert mostActiveUser(testGraph) == 1, \"the most active user was expected to be 1 but it was %s\" % mostActiveUser(testGraph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c908e0177c48d8226796d4225557c641",
     "grade": false,
     "grade_id": "cell-fddb53cc607c150e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Connection Ratio\n",
    "`connectionRatio` shows which user has the highest ratio of inward connections but fewest outward connections. \n",
    "\n",
    "param `graph`: GraphFrame containing social data.\n",
    "\n",
    "`return` DataFrame which has columns \"id\" and \"connectionRatio\", where \"id\" is the id of a user and \"connectionRatio\" = number of inward connections/number of outward connections. Users without inward or outward connections should be filtered out. **The DaraFrame should be sorted by connectionRatio in descending order. If more than one users have the same connection ratio, these users should be sorted by their id in ascending order.**\n",
    "\n",
    "example output:\n",
    "\n",
    "| id|   connectionRatio|\n",
    "|---|------------------|\n",
    "| 10|               2.0|\n",
    "|  3|               1.0|\n",
    "|  7|               1.0|\n",
    "|  4|               0.5|\n",
    "|  1|0.3333333333333333|\n",
    "|  2|0.3333333333333333|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "984ccaf54e03bf4d823ba697dbe56339",
     "grade": false,
     "grade_id": "cell-a411d7e6e2dea998",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def connectionRatio(graph):\n",
    "    connections: DataFrame = graph.edges\n",
    "    outward = connections.groupBy('src').count().withColumnRenamed('count','outward')\n",
    "    inward = connections.groupBy('dst').count().withColumnRenamed('count','inward')\n",
    "    df = outward.join(inward, outward.src == inward.dst).withColumn('connectionRatio', col('inward')/col('outward'))\n",
    "    return df.select('src', 'connectionRatio').withColumnRenamed('src', 'id').sort(col('connectionRatio').desc(), col('id').asc())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "connectionRatio(graph).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30d635b3630ea60996513b5c58abf7fc",
     "grade": true,
     "grade_id": "cell-c0d199cb9cc2435e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''connectionRatio tests'''\n",
    "correct = [Row(id=10, connectionRatio=2.0),\n",
    "           Row(id=3, connectionRatio=1.0),\n",
    "           Row(id=7, connectionRatio=1.0),\n",
    "           Row(id=4, connectionRatio=0.5),\n",
    "           Row(id=1, connectionRatio=1/3),\n",
    "           Row(id=2, connectionRatio=1/3)]\n",
    "\n",
    "test = connectionRatio(testGraph)\n",
    "equalArray(test.collect(), correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b6d9e93f154107023e455eb960847855",
     "grade": false,
     "grade_id": "cell-e64a9805b487b28d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Communities\n",
    "`communities` uses [label propagation algorithm (LPA)](https://neo4j.com/blog/graph-algorithms-neo4j-label-propagation/) to detect communities for a graph. \n",
    "\n",
    "param `graph`: GraphFrame containing social data.\n",
    "\n",
    "`return`: DataFrame containing columns \"community\" and \"count\". \"community\" is the label assigned by LPA and \"count\" is the number of users who belong to the community. **The Dataframe should be sorted by \"count\" in descending order. If more than one communities have same number of users, these communities should be sorted by label in ascending order.**\n",
    "\n",
    "Note: set 5 as the number of iterations to be performed when running LPA.\n",
    "\n",
    "Example output:\n",
    "\n",
    "|community|count|\n",
    "|---------|-----|\n",
    "|        1|    4|\n",
    "|        3|    2|\n",
    "|       10|    2|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fcbb7e18f1637bc2e3a8993c9dfdf54",
     "grade": false,
     "grade_id": "cell-dac31ea7604e805f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def communities(graph):\n",
    "    result = graph.labelPropagation(5).withColumnRenamed('label', 'community').groupBy('community').count()\n",
    "    return result.select('community', 'count').sort(col('count').desc(), col('community').asc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "communities(graph).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45da79101d408eebd98be232bddae373",
     "grade": true,
     "grade_id": "cell-bbff92edb250b8a7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''communities tests'''\n",
    "correct = [Row(community=2, count=4),\n",
    "           Row(community=8, count=3),\n",
    "           Row(community=10, count=1)]\n",
    "\n",
    "equalArray(communities(testGraph).collect(), correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7c254c68c9ce3e301e985342f434069",
     "grade": false,
     "grade_id": "cell-455c7ac19e014d24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Highest Page Rank\n",
    "`highestPageRank` finds which user has the highest [PageRank](https://en.wikipedia.org/wiki/PageRank).\n",
    "\n",
    "param `graph`: GraphFrame containing social data.\n",
    "\n",
    "`return`: id of user with the highest PageRank.\n",
    "\n",
    "**Set tolerance \"tol\" as 0.0001 when using the pageRank algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f073862a44a470a908a93d5d4ff6a76b",
     "grade": false,
     "grade_id": "cell-2daff5a1e0de0a1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def highestPageRank(graph):\n",
    "    df: DataFrame = graph.pageRank(tol=0.0001).vertices\n",
    "    maxPageRank = df.groupBy().max('pagerank').first()[0]\n",
    "    df = df.filter(col('pagerank') == maxPageRank)\n",
    "    return df.first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example print\n",
    "\n",
    "highestPageRank(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f71de7f540a1b99519c8dd4c6d407cd",
     "grade": true,
     "grade_id": "cell-3054ad6ca5f7970f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''highestPageRank tests'''\n",
    "\n",
    "#graph = createGraph(testFile)\n",
    "assert highestPageRank(testGraph) == 10, \"the highest page rank was expected to be 10 but it was %s\" % highestPageRank(testGraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "067d5cf4979c9a028449a2213e620c88",
     "grade": false,
     "grade_id": "cell-57089751fdc2b300",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
